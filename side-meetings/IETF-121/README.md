# Material for IETF121 side meeting on "Handling inter-DC/Edge AI-related network traffic"

The growth in terms of number of parameters of LLM models as well as the need to use or train those models with private or protected data will require service providers operating LLM-based services to cooperate to train, specialize or serve LLM-based services accross datacenters. 
Given their structure, the number of parameters they incorporate and the collective communication librairies they are built with, LLM training and inference (or serving) network traffic has specific characteristics.

In that regard, understanding the specificities of AI-related workloads is critical to determine how to operate AI-based services in a federated setting across datacenters.

## Logistics: 
* __Room:__ Wicklow Hall 2A
* __Remote participation:__  https://ietf.webex.com/meet/ietfsidemeeting2 (IETF Webex)

## Agenda:

| Time                     | Topic                                                      |
| ---                      | ---                                                        |
| 13:30 – 13:40 _(10 min)_ | Meeting setup and introduction of the topic _(Huawei)_     |
| 13:40 – 13:55 _(15 min)_ | Presentation by Binhang Yuan _(Together AI – HKUST)_       |
| 13:55 – 14:10 _(15 min)_ | Presentation by _China Mobile_                             |
| 14:10 – 14:25 _(15 min)_ | Presentation by _CICT_                                     |
| 14:25 – 14:40 _(15 min)_ | Presentation by Luis Contreras _(Telefónica)_              |
| 14:40 – 15:00 _(20 min)_ | Discussion on challenges to address in IETF and conclusion |

